<?xml version="1.0" encoding="UTF-8"?>
<configuration debug="false">
    <!--解决debug不效果的方式 关闭状态监听-->
    <statusListener class="ch.qos.logback.core.status.NopStatusListener" />

    <!--<property name="ProName" value="web-backend" />-->
    <!--<contextName>${ProName}</contextName>-->

    <!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径-->
    <property name="LOG_HOME" value="${logs.path}"/>
    <property name="file_error_name" value="${LOG_HOME}/error_"></property>
    <property name="file_info_name" value="${LOG_HOME}/info_"></property>
    <property name="file_task_info" value="${LOG_HOME}/task_"></property>
    <property name="file_channel_info" value="${LOG_HOME}/paychannel_"></property>
    <property name="file_message_info" value="${LOG_HOME}/message_"></property>

    <!-- 控制台输出 -->
    <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%-4level] %d{yyyy-MM-dd HH:mm:ss.SSS} %file:%line - %msg%n%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <!-- file_error 按照每天生成日志文件 -->
    <appender name="file_error" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${file_error_name}</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%-4level] %d{yyyy-MM-dd HH:mm:ss.SSS} %file:%line - %msg%n%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 级别过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>  <!-- 匹配时 -->
            <onMismatch>DENY</onMismatch>   <!-- 不匹配时 -->
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- rollover daily -->
            <fileNamePattern>${file_error_name}%d{yyyy-MM-dd}_%i.log</fileNamePattern>
            <!-- each file should be at most 100MB, keep 60 days worth of history, but at most 20GB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>15</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
    </appender>

    <!-- file_info 按照每天生成日志文件 -->
    <appender name="file_info" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${file_info_name}</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%-4level] %d{yyyy-MM-dd HH:mm:ss.SSS} %file:%line - %msg%n%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 级别过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>  <!-- 匹配时 -->
            <onMismatch>DENY</onMismatch>   <!-- 不匹配时 -->
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- rollover daily -->
            <fileNamePattern>${file_info_name}%d{yyyy-MM-dd}_%i.log</fileNamePattern>
            <!-- each file should be at most 100MB, keep 60 days worth of history, but at most 20GB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>15</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
    </appender>

    <!-- file_task_info 按照每天生成日志文件 -->
    <appender name="file_task_info" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${file_task_info}</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%-4level] %d{yyyy-MM-dd HH:mm:ss.SSS} %file:%line - %msg%n%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 级别过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>  <!-- 匹配时 -->
            <onMismatch>DENY</onMismatch>   <!-- 不匹配时 -->
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- rollover daily -->
            <fileNamePattern>${file_task_info}%d{yyyy-MM-dd}_%i.log</fileNamePattern>
            <!-- each file should be at most 100MB, keep 60 days worth of history, but at most 20GB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>15</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
    </appender>

    <!-- file_channel_info 按照每天生成日志文件 -->
    <appender name="file_channel_info" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${file_channel_info}</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%-4level] %d{yyyy-MM-dd HH:mm:ss.SSS} %file:%line - %msg%n%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 级别过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>  <!-- 匹配时 -->
            <onMismatch>DENY</onMismatch>   <!-- 不匹配时 -->
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- rollover daily -->
            <fileNamePattern>${file_channel_info}%d{yyyy-MM-dd}_%i.log</fileNamePattern>
            <!-- each file should be at most 100MB, keep 60 days worth of history, but at most 20GB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>15</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
    </appender>

    <!-- file_message_info 按照每天生成日志文件 -->
    <appender name="file_message_info" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${file_message_info}</file>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>[%-4level] %d{yyyy-MM-dd HH:mm:ss.SSS} %file:%line - %msg%n%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 级别过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>  <!-- 匹配时 -->
            <onMismatch>DENY</onMismatch>   <!-- 不匹配时 -->
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- rollover daily -->
            <fileNamePattern>${file_message_info}%d{yyyy-MM-dd}_%i.log</fileNamePattern>
            <!-- each file should be at most 100MB, keep 60 days worth of history, but at most 20GB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>15</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
    </appender>

    <!-- Application Loggers -->
    <!--<logger name="org.springframework" level="WARN"/>-->

    <!-- 异步通知,精确设置每个包下面的日志 -->
    <logger name="task_info" additivity="false">
        <appender-ref ref="file_task_info"/>
    </logger>
    <logger name="paychannel" additivity="false">
        <appender-ref ref="file_channel_info"/>
    </logger>
    <logger name="message" additivity="false">
        <appender-ref ref="file_message_info"/>
    </logger>
    <!-- 从高到地低 OFF 、 FATAL 、 ERROR 、 WARN 、 INFO 、 DEBUG 、 TRACE 、 ALL -->
    <!-- 日志输出规则  根据当前ROOT 级别，日志输出时，级别高于root默认的级别时  会输出 -->
    <!-- 以下  每个配置的 filter 是过滤掉输出文件里面，会出现高级别文件，依然出现低级别的日志信息，通过filter 过滤只记录本级别的日志-->
    <logger name="org.mybatis" level="WARN"/>
    <logger name="org.springframework" level="WARN"/>

    <!-- 日志输出级别 -->
    <root level="INFO">
        <!-- 控制台输出 -->
        <!--<appender-ref ref="console" />-->
        <!-- 文件输出 -->
        <appender-ref ref="file_error"/>
        <appender-ref ref="file_info"/>
    </root>
</configuration>